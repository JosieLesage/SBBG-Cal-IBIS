---
title: "Clean all plant records"
author: "Josie Lesage"
date: "12/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = TRUE)

# Setup packages
library(rgbif)
library(tidyverse)
```

# CCH2 Data

## Cleaning data and removing potential duplicates
The code below should be run after you have downloaded datasets for each of the islands using the spatial/WKT module, and through the terms searches in the CCH2 database.

****
To begin, use ctrl+F to find and *replace all* of the previous dates (for instance, "Dec 2020") with the new date ("Mar 2020").
****


# Term Data
To clean and generate a single data file, we must begin by extracting each zip file to its folder. 
```{r CCH2 unzip}

zipfiles <- list.files("Data/Dec 2020/CCH2/Terms", pattern = "*.zip")

print(zipfiles)

walk(zipfiles, ~ unzip(zipfile = str_c("Data/Dec 2020/CCH2/Terms/", .x),
                       exdir = str_c("Data/Dec 2020/CCH2/Terms/Unzipped/", .x),
                       overwrite = TRUE))
```

Now, we extract the occurrence data for each file, and glue all of the data together.


```{r extract csvs and glue}
occpath <- "Data/Dec 2020/CCH2/Terms/Unzipped/"
occdirs <- list.files(occpath)

cch2_terms <- read_csv("Data/Dec 2020/CCH2/Headers.csv", col_types = cols(.default = "c"))

for(dir in occdirs) {
  sub_folders = list.files(paste(occpath,dir,sep = ""))
  if (any(sub_folders %in% "occurrences.csv")) {
    ## there is occurrences.csv in this directory read it in and append to a data.frame.
    ## read in data 
    temp_data = read_csv(file = paste(occpath,dir,"/occurrences.csv",sep = ""), col_types = cols(.default = "c"))
    ## append
    cch2_terms = rbind(cch2_terms,temp_data);
  } else {
    ## try go one more directory deeper
    for(sub_dir in sub_folders) {
      sub_sub_files = list.files(paste(occpath,dir,"/",sub_dir,sep = ""))             
      if (any(sub_sub_files %in% "occurrences.csv")) {
        ## found occurrences.csv read it in and append it
        temp_data = read.csv(file = paste(occpath,dir,"/",sub_dir,"/occurrences.csv",sep = ""))
        cch2_terms = rbind(cch2_terms,temp_data);
      } else {
        warning("could not find the file 'occurrences.csv' two directories deep")
      }
    } 
  }
}

```


Voila, "cch2_terms" is a huge dataset and has everyone (but probably some dupes). 

# Spatial/WKT data

There are fewer WKT datasets, but we need to extact and glue them too. 
```{r unzip WKTs}
unzip("Data/Dec 2020/CCH2/WKTs/Barbara.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Barbara")
unzip("Data/Dec 2020/CCH2/WKTs/Benito.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Benito")
unzip("Data/Dec 2020/CCH2/WKTs/Catalina.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Catalina")
unzip("Data/Dec 2020/CCH2/WKTs/Clemente.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Clemente")
unzip("Data/Dec 2020/CCH2/WKTs/Coronados.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Coronados")
unzip("Data/Dec 2020/CCH2/WKTs/Geronimo.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Geronimo")
unzip("Data/Dec 2020/CCH2/WKTs/Guadalupe.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Guadalupe")
unzip("Data/Dec 2020/CCH2/WKTs/Martin.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Martin")
unzip("Data/Dec 2020/CCH2/WKTs/Miguel_Rosa_Cruz.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Miguel_Rosa_Cruz")
unzip("Data/Dec 2020/CCH2/WKTs/Natividad_Cedros.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Natividad_Cedros")
unzip("Data/Dec 2020/CCH2/WKTs/Nicolas.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Nicolas")
unzip("Data/Dec 2020/CCH2/WKTs/Todos_Santos.zip", exdir = "Data/Dec 2020/CCH2/WKTs/Todos_Santos")
```

```{r import WKTs}
Barbara_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Barbara/occurrences.csv", col_types = cols(.default = "c"))
Benito_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Benito/occurrences.csv", col_types = cols(.default = "c"))
Catalina_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Catalina/occurrences.csv", col_types = cols(.default = "c"))
Clemente_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Clemente/occurrences.csv", col_types = cols(.default = "c"))
Coronados_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Coronados/occurrences.csv", col_types = cols(.default = "c"))
Geronimo_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Geronimo/occurrences.csv", col_types = cols(.default = "c"))
Guadalupe_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Guadalupe/occurrences.csv", col_types = cols(.default = "c"))
Martin_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Martin/occurrences.csv", col_types = cols(.default = "c"))
Miguel_Rosa_Cruz_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Miguel_Rosa_Cruz/occurrences.csv", col_types = cols(.default = "c"))
Natividad_Cedros_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Natividad_Cedros/occurrences.csv", col_types = cols(.default = "c"))
Nicolas_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Nicolas/occurrences.csv", col_types = cols(.default = "c"))
Todos_Santos_WKT <- read_csv("Data/Dec 2020/CCH2/WKTs/Todos_Santos/occurrences.csv", col_types = cols(.default = "c"))
```

```{r glue WKTs}
cch2_wkts <- full_join(Barbara_WKT, Benito_WKT)
cch2_wkts <- full_join(cch2_wkts, Catalina_WKT)
cch2_wkts <- full_join(cch2_wkts, Clemente_WKT)
cch2_wkts <- full_join(cch2_wkts, Coronados_WKT)
cch2_wkts <- full_join(cch2_wkts, Geronimo_WKT)
cch2_wkts <- full_join(cch2_wkts, Guadalupe_WKT)
cch2_wkts <- full_join(cch2_wkts, Martin_WKT)
cch2_wkts <- full_join(cch2_wkts, Miguel_Rosa_Cruz_WKT)
cch2_wkts <- full_join(cch2_wkts, Natividad_Cedros_WKT)
cch2_wkts <- full_join(cch2_wkts, Nicolas_WKT)
cch2_wkts <- full_join(cch2_wkts, Todos_Santos_WKT)
```

# The final gluing

Now that we have both a CCH2 term and a CCH2 WKT dataset, we need to remove as many duplicates as we possibly can. 

```{r dupe clear}
cch2_all <- full_join(cch2_terms, cch2_wkts)
cch2_all_dist <- distinct(cch2_all, id, .keep_all = TRUE)
cch2_all_dist_2 <- distinct(cch2_all_dist, occurrenceID, .keep_all = TRUE)

write.csv(cch2_all_dist_2, file = "Data/Dec 2020/CCH2/CCH_Clean.csv", na="", row.names=FALSE)
```

