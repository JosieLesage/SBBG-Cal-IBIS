---
title: "GBIF-DataDownload"
author: "Josie Lesage"
date: "10/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = TRUE)

# Put packages up
library(rgbif)
library(spocc)
```

# File goal

This file is intended to gather GBIF records for species on the California Channel Islands, which will be used to update the Cal-IBIS repository. 

# Gathering GBIF Data

To begin, we'll gather the data we're interested in from GBIF. We'll download three separate datasets:
1. Fungi
2. Arthropods
3. Plants

Because we want only data that have coordinate information, we'll remove all data that are missing coordinates ("NA"). 

```{r setup and data download}
# set your working directory to where ever your csv is saved to.
setwd ("C:/Users/Josie/Dropbox/SBBG/Cal-IBIS/Cal_IBIS/NAU documents/R_scripts")

### extracting non-NA georefrenced records###
### use this step below or you can download the Darwin Core data set from GBIF using the the appropriate polygon
df2 <- occ_data(taxonKey= 131, geometry = 'POLYGON((-121.67358 33.89282,
                                               -119.27856 28.57544,
                                               -117.65259 27.67456,
                                               -115.16418 27.76794,
                                               -114.62036 28.28979, 
                                               -116.02661 29.14673,
                                               -116.15295 29.72351,
                                               -116.97144 31.38794,
                                               -118.34747 33.57697,
                                               -119.43787 34.16199,
                                               -120.31128 34.24438,
                                               -121.67358 33.89282))',
                limit = 20)

df2 <- occ_download(taxonKey = '131')
df1 <- occ_get(key ='131')



name_usage(key = 131)
```


## Removing dupes for FUNGI
The code chunk below will remove the duplicated occurrence records for all fungi records gathered from GBIF that are already present in the datasets downloaded from other sources. To do this, we will directly call on the other dataset data and remove all duplicates from the data we downloaded from GBIF above. 

```{r removing duplicates from Fungi}
#read in your darwin core occurrence records csv (usually titled occurrence.txt in zip file)
fungi <- read.csv("occurrence_fungi.csv") 
inCode <- read.csv ("NA_inCodes_updated2020.csv")


fungi2 <- fungi[!(is.na(fungi$institutionCode)),]

#i = 347
for (i in c(1:971)) {
  fungi2 = fungi2[fungi2$institutionCode != paste(inCode[i,1]),]
}


for (i in c(1:971)) {
  fungi2 = fungi2[fungi2$collectionCode != paste(inCode[i,2]), ]
}

write.csv (fungi2, file = "cleaned_fungi_nonNA.csv", na="")
```


## Removing dupes for ARTHROPODS
```{r removing duplicates from Bugs}
#read in your darwin core occurrence records csv (usually titled occurrence.txt in zip file)
arthropods = read.csv("occurrence_arthropods.csv")
inCode = read.csv("NA_inCodes_updated2020.csv")

arthropods2 <- arthropods[!(is.na(arthropods$institutionCode)),]

#i =347
for (i in c(1:971)) {
  arthropods2 = arthropods2[arthropods2$institutionCode != paste(inCode[i,1]),]
}


for (i in c(1:971)) {
  arthropods2 = arthropods2[arthropods2$collectionCode != paste(inCode[i,2]), ]
}

write.csv (arthropods2, file = "cleaned_arthropods_nonNA.csv", na="")
```


## Removing dupes for PLANTS
```{r removing duplicates from Plants}
#read in your darwin core occurence records csv (usually titled occurrence.txt in zip file)
plants = read.csv("occurrence_plants.csv") 
inCode = read.csv("NA_inCodes_updated2020.csv")

plants2 <- plants[!(is.na(plants$institutionCode)),]

#i = 347
for (i in c(1:971)) {
  plants2 = plants2[plants2$institutionCode != paste(inCode[i,1]),]
}


for (i in c(1:971)) {
  plants2 = plants2[plants2$collectionCode != paste(inCode[i,2]), ]
}

write.csv (plants2, file = "cleaned_plants_nonNA.csv", na="")
```


